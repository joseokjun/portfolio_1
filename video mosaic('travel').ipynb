{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "from vision.ssd.config.fd_config import define_img_size\n",
    "global i\n",
    "\n",
    "i = 0\n",
    "x_pos_ = []\n",
    "y_pos_ = []\n",
    "x_dis_ = []#x점 두 개 사이의 거리\n",
    "y_dis_ = []#y점 두 개 사이의 거리\n",
    "\n",
    "\n",
    "###성능 테스트###\n",
    "nowtime = time.time()\n",
    "face_count = 0\n",
    "total_frame = 0\n",
    "\n",
    "\n",
    "###############################\n",
    "#input_img_size = args.input_size\n",
    "input_img_size = 320\n",
    "threshold = 0.7\n",
    "candidate_size = 1000\n",
    "\n",
    "define_img_size(input_img_size)  # must put define_img_size() before 'import create_mb_tiny_fd, create_mb_tiny_fd_predictor'\n",
    "\n",
    "from vision.ssd.mb_tiny_fd import create_mb_tiny_fd, create_mb_tiny_fd_predictor\n",
    "from vision.ssd.mb_tiny_RFB_fd import create_Mb_Tiny_RFB_fd, create_Mb_Tiny_RFB_fd_predictor\n",
    "from vision.utils.misc import Timer\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    if event == 1:\n",
    "        global x_pos_1\n",
    "        global y_pos_1\n",
    "        x_pos_1 = x\n",
    "        y_pos_1 = y\n",
    "    elif event == 4:\n",
    "        global x_pos_2\n",
    "        global y_pos_2\n",
    "        global x_dis\n",
    "        global y_dis\n",
    "        x_pos_2 = x\n",
    "        y_pos_2 = y\n",
    "        x_dis = x_pos_2 - x_pos_1\n",
    "        y_dis = y_pos_2 - y_pos_1\n",
    "#        frame_tmp2[int(capture.get(cv2.CAP_PROP_POS_FRAMES))] = [x_pos_1, y_pos_1, x_pos_2, y_pos_2]\n",
    " #       print(frame_tmp2)\n",
    "    elif flags == 8 and event == 0:\n",
    "        x_pos_1 = x - int(x_dis/2)\n",
    "        y_pos_1 = y - int(y_dis/2)\n",
    "        x_pos_2 = x + int(x_dis/2)\n",
    "        y_pos_2 = y + int(y_dis/2)\n",
    "        frame_tmp2[int(cap.get(cv2.CAP_PROP_POS_FRAMES))] = [x_pos_1, y_pos_1, x_pos_2, y_pos_2]\n",
    "    elif flags == 32 and event == 0:\n",
    "        if frame_tmp2.get(int(cap.get(cv2.CAP_PROP_POS_FRAMES))) != None:\n",
    "            global mosaic\n",
    "            mosaic = 1\n",
    "\n",
    "def get_circle_x(x1, y1, x2, y2, y):\n",
    "    a = x2 - x1\n",
    "    b = y2 - y1\n",
    "    x = ((x2 + x1) / 2 + ((x2 - x1) / 2) * (1 - ((y - (y2 + y1) / 2) ** 2) / ((y2 - y1) / 2) ** 2) ** 0.5,\n",
    "         (x2 + x1) / 2 - ((x2 - x1) / 2) * (1 - ((y - (y2 + y1) / 2) ** 2) / ((y2 - y1) / 2) ** 2) ** 0.5)\n",
    "    #    print(x)\n",
    "    return x\n",
    "\n",
    "def blur_circle(img, x1, y1, x2, y2): #모자이크 영역 설정\n",
    "    #   print(img[10, x1:int(get_circle_x(x1, y1, x2, y2, 10)[1])])\n",
    "\n",
    "    img_blur = copy.deepcopy(img)\n",
    "    #    img_blur = img[:]\n",
    "    img_blur[y1:y2, x1:x2] = cv2.blur(img_blur[y1:y2, x1:x2], (100, 100))\n",
    "\n",
    "    yi = y1\n",
    "    while True:\n",
    "        if yi == y2:\n",
    "            break\n",
    "        img[yi, round(get_circle_x(x1, y1, x2, y2, yi)[1]):round(get_circle_x(x1, y1, x2, y2, yi)[0])] = img_blur[yi,\n",
    "                                                                                                         round(\n",
    "                                                                                                             get_circle_x(\n",
    "                                                                                                                 x1, y1,\n",
    "                                                                                                                 x2, y2,\n",
    "                                                                                                                 yi)[\n",
    "                                                                                                                 1]):round(\n",
    "                                                                                                             get_circle_x(\n",
    "                                                                                                                 x1, y1,\n",
    "                                                                                                                 x2, y2,\n",
    "                                                                                                                 yi)[\n",
    "                                                                                                                 0])]\n",
    "        #        img[yi, 30:60] = img_blur[yi, 30:60]\n",
    "        yi += 1\n",
    "\n",
    "    return img\n",
    "\n",
    "def draw_circle(event, x, y, flags, param): #마우스 클릭 이벤트를 통한 모자이크 처리\n",
    "    print(i)\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # 마우스를 누른 상태\n",
    "        x_pos_.append(x)\n",
    "        y_pos_.append(y)\n",
    "\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        x_pos_.append(x)\n",
    "        y_pos_.append(y)\n",
    "\n",
    "        #         drawing = False\n",
    "        #         global x_pos_2\n",
    "        #         global y_pos_2\n",
    "        #         global x_dis\n",
    "        #         global y_dis\n",
    "        #         x_pos_2 = x\n",
    "        #         y_pos_2 = y\n",
    "\n",
    "        if x_pos_[i] > x_pos_[i + 1] and y_pos_[i] > y_pos_[i + 1]:\n",
    "            #             x_dis_[i] = x_pos_[i] - x_pos_[i+1]\n",
    "            #             y_dis_[i] = y_pos_[i] - y_pos_[i+1]\n",
    "            x_dis_.append(x_pos_[i] - x_pos_[i + 1])\n",
    "            y_dis_.append(y_pos_[i] - y_pos_[i + 1])\n",
    "        elif x_pos_[i] > x_pos_[i + 1] and y_pos_[i] < y_pos_[i + 1]:\n",
    "            #             x_dis_[i] = x_pos_[i] - x_pos_[i+1]\n",
    "            #             y_dis_[i] = y_pos_[i+1] - y_pos_[i]\n",
    "            x_dis_.append(x_pos_[i] - x_pos_[i + 1])\n",
    "            y_dis_.append(y_pos_[i + 1] - y_pos_[i])\n",
    "        elif x_pos_[i] < x_pos_[i + 1] and y_pos_[i] > y_pos_[i + 1]:\n",
    "            #             x_dis_[i] = x_pos_[i+1] - x_pos_[i]\n",
    "            #             y_dis_[i] = y_pos_[i] - y_pos_[i+1]\n",
    "            x_dis_.append(x_pos_[i + 1] - x_pos_[i])\n",
    "            y_dis_.append(y_pos_[i] - y_pos_[i + 1])\n",
    "        elif x_pos_[i] < x_pos_[i + 1] and y_pos_[i] < y_pos_[i + 1]:\n",
    "            #             x_dis_[i] = x_pos_[i+1] - x_pos_[i]\n",
    "            #             y_dis_[i] = y_pos_[i+1] - y_pos_[i]\n",
    "            x_dis_.append(x_pos_[i + 1] - x_pos_[i])\n",
    "            y_dis_.append(y_pos_[i + 1] - y_pos_[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mouse_event_types = { 0:\"EVENT_MOUSEMOVE\", 1:\"EVENT_LBUTTONDOWN\", 2:\"EVENT_RBUTTONDOWN\", 3:\"EVENT_MBUTTONDOWN\",\n",
    "                 4:\"EVENT_LBUTTONUP\", 5:\"EVENT_RBUTTONUP\", 6:\"EVENT_MBUTTONUP\",\n",
    "                 7:\"EVENT_LBUTTONDBLCLK\", 8:\"EVENT_RBUTTONDBLCLK\", 9:\"EVENT_MBUTTONDBLCLK\",\n",
    "                 10:\"EVENT_MOUSEWHEEL\", 11:\"EVENT_MOUSEHWHEEL\"}\n",
    "mouse_event_flags = { 0:\"None\", 1:\"EVENT_FLAG_LBUTTON\", 2:\"EVENT_FLAG_RBUTTON\", 4:\"EVENT_FLAG_MBUTTON\",\n",
    "                8:\"EVENT_FLAG_CTRLKEY\", 9:\"EVENT_FLAG_CTRLKEY + EVENT_FLAG_LBUTTON\",\n",
    "                10:\"EVENT_FLAG_CTRLKEY + EVENT_FLAG_RBUTTON\", 11:\"EVENT_FLAG_CTRLKEY + EVENT_FLAG_MBUTTON\",\n",
    "                16:\"EVENT_FLAG_SHIFTKEY\", 17:\"EVENT_FLAG_SHIFTKEY + EVENT_FLAG_LBUTTON\",\n",
    "                18:\"EVENT_FLAG_SHIFTLKEY + EVENT_FLAG_RBUTTON\", 19:\"EVENT_FLAG_SHIFTKEY + EVENT_FLAG_MBUTTON\",\n",
    "                32:\"EVENT_FLAG_ALTKEY\", 33:\"EVENT_FLAG_ALTKEY + EVENT_FLAG_LBUTTON\",\n",
    "                34:\"EVENT_FLAG_ALTKEY + EVENT_FLAG_RBUTTON\", 35:\"EVENT_FLAG_ALTKEY + EVENT_FLAG_MBUTTON\"}\n",
    "\n",
    "label_path = \"./models/voc-model-labels.txt\"\n",
    "\n",
    "#####################\n",
    "#net_type = args.net_type\n",
    "net_type = 'slim'\n",
    "\n",
    "\n",
    "##############경로 수정함###########\n",
    "#cap = cv2.VideoCapture(args.video_path)  # capture from video\n",
    "#cap = cv2.VideoCapture(0)  # capture from camera / webcam\n",
    "file_name = 'travel.mp4'\n",
    "cap = cv2.VideoCapture(file_name) # capture from video\n",
    "\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX') #if you want to use DIVX codec to decode .avi\n",
    "out = cv2.VideoWriter('SAVE_travel.avi', fourcc, fps, (int(width), int(height)))\n",
    "\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'MPEG')\n",
    "#out = cv2.VideoWriter('SAVE_travel.mp4', fourcc, fps, (int(width), int(height)))\n",
    "\n",
    "################################\n",
    "class_names = [name.strip() for name in open(label_path).readlines()]\n",
    "num_classes = len(class_names)\n",
    "#test_device = args.test_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "priors nums:4420\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a6097bc413cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"models/pretrained/version-slim-320.pth\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;31m# model_path = \"models/pretrained/version-slim-640.pth\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_mb_tiny_fd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_mb_tiny_fd_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcandidate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Corona\\Ainado-master\\project_ainado\\vision\\ssd\\mb_tiny_fd.py\u001b[0m in \u001b[0;36mcreate_mb_tiny_fd\u001b[1;34m(num_classes, is_test, device)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     return SSD(num_classes, base_net_model, source_layer_indexes,\n\u001b[1;32m---> 53\u001b[1;33m                extras, classification_headers, regression_headers, is_test=is_test, config=config, device=device)\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Corona\\Ainado-master\\project_ainado\\vision\\ssd\\ssd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_classes, base_net, source_layer_indexes, extras, classification_headers, regression_headers, is_test, config, device)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpriors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpriors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\corona\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;31m# are found or any other error occurs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;31m# we need to just return without initializing in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "test_device = 'cuda'\n",
    "\n",
    "#candidate_size = args.candidate_size\n",
    "#threshold = args.threshold\n",
    "\n",
    "frame_tmp = []\n",
    "frame_tmp2 = {}\n",
    "proc = 0 #현재 진행 상황\n",
    "###전체 불러오기\n",
    "\n",
    "x_pos_1, y_pos_1, x_pos_2, y_pos_2 = 0 ,0 ,1,1\n",
    "\n",
    "mosaic = False\n",
    "video_speed = 10 #1 이상의 정수\n",
    "\n",
    "if net_type == 'slim': #ultra fast light 모드 중 하나, slim이 더 빠름\n",
    "    model_path = \"models/pretrained/version-slim-320.pth\"\n",
    "    # model_path = \"models/pretrained/version-slim-640.pth\"\n",
    "    net = create_mb_tiny_fd(len(class_names), is_test=True, device=test_device)\n",
    "    predictor = create_mb_tiny_fd_predictor(net, candidate_size=candidate_size, device=test_device)\n",
    "\n",
    "elif net_type == 'RFB':\n",
    "    model_path = \"models/pretrained/version-RFB-320.pth\"\n",
    "    # model_path = \"models/pretrained/version-RFB-640.pth\"\n",
    "    net = create_Mb_Tiny_RFB_fd(len(class_names), is_test=True, device=test_device)\n",
    "    predictor = create_Mb_Tiny_RFB_fd_predictor(net, candidate_size=candidate_size, device=test_device)\n",
    "\n",
    "else:\n",
    "    print(\"The net type is wrong!\")\n",
    "    sys.exit(1)\n",
    "net.load(model_path)\n",
    "\n",
    "\n",
    "timer = Timer()\n",
    "sum = 0\n",
    "cap = cv2.VideoCapture(file_name) # capture from video\n",
    "total_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, orig_image= cap.read()\n",
    "    frame_tmp.append(orig_image)\n",
    "    orig_image_tmp = copy.deepcopy(orig_image)\n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) == 300:\n",
    "       break\n",
    "    if not ret:\n",
    "        break\n",
    "    proc += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cap = cv2.VideoCapture(file_name) # capture from video\n",
    "cv2.namedWindow(file_name)\n",
    "cv2.createTrackbar('Frame', file_name, 0, total_frame, nothing)\n",
    "cv2.createTrackbar(\"Pause\", file_name, 0, 1, nothing)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, orig_image = cap.read()\n",
    "    cv2.setMouseCallback(file_name, mouse_callback)\n",
    "    cv2.setMouseCallback(file_name, draw_circle)\n",
    "    p = cv2.getTrackbarPos('Pause', file_name)\n",
    "    r = cv2.getTrackbarPos('Frame', file_name)\n",
    "\n",
    "    timer.start()\n",
    "    image =cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "    boxes, labels, probs = predictor.predict(image, candidate_size / 2, threshold)\n",
    "    interval = timer.end()\n",
    "    r = r + 1\n",
    "    cv2.setTrackbarPos('Frame', file_name, r)\n",
    "\n",
    "    #cap.set(cv2.CAP_PROP_POS_FRAMES, r)\n",
    "    #cv2.setTrackbarPos('Pause', file_name, p)\n",
    "    #cv2.getTrackbarPos('Frame', file_name)\n",
    "\n",
    "    for i in range(boxes.size(0)):\n",
    "        box = boxes[i, :]\n",
    "        #   label = f\" {probs[i]:.2f}\"\n",
    "        if box[1] < 0:\n",
    "            box[1] = 0\n",
    "        if box[0] < 0:\n",
    "            box[0] = 0\n",
    "\n",
    "        #        blur_img = cv2.blur(orig_image[int(box[1]):int(box[3]), int(box[0]):int(box[2])], (100, 100))\n",
    "        #        orig_image[int(box[1]):int(box[3]), int(box[0]):int(box[2])] = blur_circle(orig_image[int(box[1]):int(box[3]), int(box[0]):int(box[2])], int(box[1]), int(box[3]), int(box[0]), int(box[2]))\n",
    "        orig_image = blur_circle(orig_image, int(box[0]), int(box[1]), int(box[2]), int(box[3]))\n",
    "\n",
    "    sum += boxes.size(0)\n",
    "\n",
    "    if len(x_pos_) != 0:\n",
    "        for i in range(len(x_pos_) - 1):\n",
    "            if i % 2 != 0: continue\n",
    "            if y_pos_[i] > y_pos_[i + 1] and x_pos_[i] > x_pos_[i + 1]:\n",
    "                orig_image[y_pos_[i + 1]:y_pos_[i], x_pos_[i + 1]:x_pos_[i]] = cv2.blur(\n",
    "                    orig_image[y_pos_[i + 1]:y_pos_[i], x_pos_[i + 1]:x_pos_[i]], (100, 100))\n",
    "            elif y_pos_[i] > y_pos_[i + 1] and x_pos_[i] < x_pos_[i + 1]:\n",
    "                orig_image[y_pos_[i + 1]:y_pos_[i], x_pos_[i]:x_pos_[i + 1]] = cv2.blur(\n",
    "                    orig_image[y_pos_[i + 1]:y_pos_[i], x_pos_[i]:x_pos_[i + 1]], (100, 100))\n",
    "            elif y_pos_[i] < y_pos_[i + 1] and x_pos_[i] > x_pos_[i + 1]:\n",
    "                orig_image[y_pos_[i]:y_pos_[i + 1], x_pos_[i + 1]:x_pos_[i]] = cv2.blur(\n",
    "                    orig_image[y_pos_[i]:y_pos_[i + 1], x_pos_[i + 1]:x_pos_[i]], (100, 100))\n",
    "            elif y_pos_[i] < y_pos_[i + 1] and x_pos_[i] < x_pos_[i + 1]:\n",
    "                orig_image[y_pos_[i]:y_pos_[i + 1], x_pos_[i]:x_pos_[i + 1]] = cv2.blur(\n",
    "                    orig_image[y_pos_[i]:y_pos_[i + 1], x_pos_[i]:x_pos_[i + 1]], (100, 100))\n",
    "      i = i + 2\n",
    "\n",
    "    #frame = frame_tmp[r]\n",
    "\n",
    "    out.write(orig_image)\n",
    "\n",
    "\n",
    "    #    print(cap.get(cv2.CAP_PROP_POS_AVI_RATIO))\n",
    "\n",
    "    if p == 0:\n",
    "        cv2.waitKey(-1)\n",
    "\n",
    "    if cv2.waitKey(1) > 0:\n",
    "\n",
    "        break\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, r)\n",
    "    cv2.imshow(file_name, orig_image)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
